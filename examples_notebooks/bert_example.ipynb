{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sequence classification with *NeuralNetTrainer* #\n",
    "\n",
    "### To fine-tune a model using *NeuralNetTrainer*, we need to follow four steps: ###\n",
    "1. initialize backbone\n",
    "2. prepare data\n",
    "3. initialize optimizer and specify functions for bert model\n",
    "4. initialize model with *NeuralNetTrainer*\n",
    "\n",
    "after these steps the model can be fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from transformers import  AdamW\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datetime import datetime\n",
    "from NeuralNetTrainer import NeuralNetTrainer\n",
    "\n",
    "from torchmetrics.functional import accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. initialize backbone ####\n",
    "I will use xlm-roberta-base from [huggingface](https://huggingface.co/xlm-roberta-base)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    "    num_labels=5\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. prepare data ####"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def from_numbers_to_string(x):\n",
    "    if x<30:\n",
    "        return \"new\"\n",
    "    if (x>=30) and (x<75):\n",
    "        return \"recently\"\n",
    "    if (x>=75) and (x<120):\n",
    "        return \"not long ago\"\n",
    "    if (x>=120) and (x<165):\n",
    "        return \"middle\"\n",
    "    if (x>=165) and (x<200):\n",
    "        return \"almost old\"\n",
    "    if x>=200:\n",
    "        return \"old\"\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna()\n",
    "    df['at'] = df['at'].map(lambda x: x[0:10])\n",
    "    datetime_object_now = datetime.strptime('2022 03 20', '%Y %m %d')\n",
    "    df['at'] = list(map(lambda x: (datetime_object_now - datetime.strptime(str(x).replace('-', ' '), '%Y %m %d')).days, df['at']))\n",
    "    df['at'] = df['at'].map(lambda x: from_numbers_to_string(x))\n",
    "    sentences = ['[CLS]' + df['content'].iloc[i]+ '[SEP]' + df['at'].iloc[i] for i in range(len(df))]\n",
    "    cat_c = 'score'\n",
    "\n",
    "    if cat_c in list(df):\n",
    "        labels = [x-1 for x in df[cat_c].values]\n",
    "        return sentences, labels\n",
    "    else:\n",
    "        return sentences\n",
    "\n",
    "def prepare_data(sentences, labels=None):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in tqdm(sentences):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,                      # Sentence to encode.\n",
    "            add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
    "            max_length = 50,           # Pad & truncate all sentences.\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,   # Construct attn. masks.\n",
    "            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "        )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    if labels is None:\n",
    "        return input_ids, attention_masks\n",
    "    else:\n",
    "        labels = torch.tensor(labels)\n",
    "        return input_ids, attention_masks, labels\n",
    "\n",
    "def load():\n",
    "    global train_sentences,val_sentences,train_labels,val_labels\n",
    "    train_sentences, train_labels = load_data('coment_mark/review_train.csv')\n",
    "    train_sentences,val_sentences,train_labels,val_labels=train_test_split(train_sentences,train_labels, train_size=0.8)\n",
    "\n",
    "def prepare():\n",
    "    global train_input_ids, train_attention_masks, train_labels,val_input_ids, val_attention_masks, val_labels, train_sentences, val_sentences\n",
    "    train_input_ids, train_attention_masks, train_labels = prepare_data(train_sentences, train_labels)\n",
    "    val_input_ids, val_attention_masks, val_labels = prepare_data(val_sentences, val_labels)\n",
    "\n",
    "def load_and_tok_for_pred():\n",
    "    global test_input_ids, test_attention_masks\n",
    "    sentences = load_data('coment_mark/review_test.csv')\n",
    "    test_input_ids, test_attention_masks = prepare_data(sentences)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load()\n",
    "prepare()\n",
    "load_and_tok_for_pred()\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. initialize optimizer and *specify functions for bert model* ####"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = AdamW(bert_model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                  )\n",
    "\n",
    "def forward_fn(model, batch):\n",
    "    input_ids = batch[0]\n",
    "    input_mask = batch[1]\n",
    "    labels = batch[2]\n",
    "    result = model(input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=input_mask,\n",
    "                    labels=labels,\n",
    "                    return_dict=True\n",
    "                   )\n",
    "    return result\n",
    "\n",
    "def get_loss_fn(segmenter_object, preds, batch):\n",
    "    return preds.loss\n",
    "\n",
    "def get_acc_fn(segmenter_object, preds, batch):\n",
    "    target = batch[2]\n",
    "    preds = preds.logits\n",
    "    acc = accuracy(preds.squeeze(), F.one_hot(target.squeeze(), num_classes=5), task=segmenter_object.task, num_labels=segmenter_object.num_labels,\n",
    "                   num_classes=segmenter_object.num_classes)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. initialize model with *NeuralNetTrainer* ####"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you specify forward step then you should generally specify 'specify_get_loss', and 'specify_get_accuracy'\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetTrainer(\n",
    "    backbone=bert_model,\n",
    "    optimizer=optimizer,\n",
    "    train_torch_dataset=train_dataset,\n",
    "    val_torch_dataset=val_dataset,\n",
    "    pred_torch_dataset=test_dataset,\n",
    "    task='multilabel',\n",
    "    num_labels=5,\n",
    "    specify_forward_step=forward_fn,\n",
    "    specify_get_loss=get_loss_fn,\n",
    "    specify_get_accuracy=get_acc_fn,\n",
    "    batch_size=128\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    min_epochs=1,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}